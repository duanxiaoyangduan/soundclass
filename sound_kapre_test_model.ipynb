{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TimeDistributed, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from kapre.utils import Normalization2D\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv1D(N_CLASSES=10, SR=16000, DT=1.0):\n",
    "    i = layers.Input(shape=(1, int(SR*DT)), name='input')\n",
    "    x = Melspectrogram(n_dft=512, n_hop=160,\n",
    "                       padding='same', sr=SR, n_mels=128,\n",
    "                       fmin=0.0, fmax=SR/2, power_melgram=2.0,\n",
    "                       return_decibel_melgram=True, trainable_fb=False,\n",
    "                       trainable_kernel=False,\n",
    "                       name='melbands')(i)\n",
    "    x = Normalization2D(str_axis='batch', name='batch_norm')(x)\n",
    "    x = layers.Permute((2,1,3), name='permute')(x)\n",
    "    x = TimeDistributed(layers.Conv1D(8, kernel_size=(4), activation='tanh'), name='td_conv_1d_tanh')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_1')(x)\n",
    "    x = TimeDistributed(layers.Conv1D(16, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_1')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_2')(x)\n",
    "    x = TimeDistributed(layers.Conv1D(32, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_2')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_3')(x)\n",
    "    x = TimeDistributed(layers.Conv1D(64, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_3')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_4')(x)\n",
    "    x = TimeDistributed(layers.Conv1D(128, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_4')(x)\n",
    "    x = layers.GlobalMaxPooling2D(name='global_max_pooling_2d')(x)\n",
    "    x = layers.Dropout(rate=0.1, name='dropout')(x)\n",
    "    x = layers.Dense(64, activation='relu', activity_regularizer=l2(0.001), name='dense')(x)\n",
    "    o = layers.Dense(N_CLASSES, activation='softmax', name='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=i, outputs=o, name='1d_convolution')\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def Conv2D(N_CLASSES=10, SR=16000, DT=1.0):\n",
    "    initializer = tf.keras.initializers.TruncatedNormal(seed=None)\n",
    "    \n",
    "    i = layers.Input(shape=(1, int(SR*DT)), name='input')\n",
    "    x = Melspectrogram(n_dft=512, n_hop=160,\n",
    "                       padding='same', sr=SR, n_mels=128,\n",
    "                       fmin=0.0, fmax=SR/2, power_melgram=2.0,\n",
    "                       return_decibel_melgram=True, trainable_fb=False,\n",
    "                       trainable_kernel=False,\n",
    "                       name='melbands')(i)\n",
    "    x = Normalization2D(str_axis='batch', name='batch_norm')(x)\n",
    "    x = layers.Conv2D(8, kernel_size=(7,7), activation='tanh',kernel_initializer=initializer, padding='same', name='conv2d_tanh')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_1')(x)\n",
    "    x = layers.Conv2D(16, kernel_size=(5,5), activation='relu',kernel_initializer=initializer, padding='same', name='conv2d_relu_1')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_2')(x)\n",
    "    x = layers.Conv2D(16, kernel_size=(3,3), activation='relu',kernel_initializer=initializer, padding='same', name='conv2d_relu_2')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_3')(x)\n",
    "    x = layers.Conv2D(32, kernel_size=(3,3), activation='relu',kernel_initializer=initializer, padding='same', name='conv2d_relu_3')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_4')(x)\n",
    "    x = layers.Conv2D(32, kernel_size=(3,3), activation='relu',kernel_initializer=initializer, padding='same', name='conv2d_relu_4')(x)\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dropout(rate=0.5, name='dropout')(x)\n",
    "    x = layers.Dense(64, activation='relu',kernel_initializer=initializer, activity_regularizer=l2(0.001), name='dense')(x)\n",
    "    o = layers.Dense(N_CLASSES,kernel_initializer=initializer, activation='softmax', name='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=i, outputs=o, name='2d_convolution')\n",
    "    model.summary()\n",
    "    initial_learning_rate = 0.1\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate,\n",
    "        decay_steps=500,\n",
    "        decay_rate=0.94,\n",
    "        staircase=True)\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adagrad(learning_rate=lr_schedule)\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def LSTM(N_CLASSES=10, SR=16000, DT=1.0):\n",
    "    i = layers.Input(shape=(1, int(SR*DT)), name='input')\n",
    "    x = Melspectrogram(n_dft=512, n_hop=160,\n",
    "                       padding='same', sr=SR, n_mels=128,\n",
    "                       fmin=0.0, fmax=SR/2, power_melgram=2.0,\n",
    "                       return_decibel_melgram=True, trainable_fb=False,\n",
    "                       trainable_kernel=False,\n",
    "                       name='melbands')(i)\n",
    "    x = Normalization2D(str_axis='batch', name='batch_norm')(x)\n",
    "    x = layers.Permute((2,1,3), name='permute')(x)\n",
    "    x = TimeDistributed(layers.Reshape((-1,)), name='reshape')(x)\n",
    "    s = TimeDistributed(layers.Dense(64, activation='tanh'),\n",
    "                        name='td_dense_tanh')(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(32, return_sequences=True),\n",
    "                             name='bidirectional_lstm')(s)\n",
    "    x = layers.concatenate([s, x], axis=2, name='skip_connection')\n",
    "    x = layers.Dense(64, activation='relu', name='dense_1_relu')(x)\n",
    "    x = layers.MaxPooling1D(name='max_pool_1d')(x)\n",
    "    x = layers.Dense(32, activation='relu', name='dense_2_relu')(x)\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dropout(rate=0.2, name='dropout')(x)\n",
    "    x = layers.Dense(32, activation='relu',\n",
    "                         activity_regularizer=l2(0.001),\n",
    "                         name='dense_3_relu')(x)\n",
    "    o = layers.Dense(N_CLASSES, activation='softmax', name='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=i, outputs=o, name='long_short_term_memory')\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from models import Conv1D, Conv2D, LSTM\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import argparse\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, wav_paths, labels, sr, dt, n_classes,\n",
    "                 batch_size=32, shuffle=True):\n",
    "        self.wav_paths = wav_paths\n",
    "        self.labels = labels\n",
    "        self.sr = sr\n",
    "        self.dt = dt\n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = True\n",
    "        self.on_epoch_end()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.wav_paths) / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        wav_paths = [self.wav_paths[k] for k in indexes]\n",
    "        labels = [self.labels[k] for k in indexes]\n",
    "\n",
    "        # generate a batch of time data\n",
    "        X = np.empty((self.batch_size, 1, int(self.sr*self.dt)), dtype=np.float32)\n",
    "        Y = np.empty((self.batch_size, self.n_classes), dtype=np.float32)\n",
    "\n",
    "        for i, (path, label) in enumerate(zip(wav_paths, labels)):\n",
    "            #print(path+str(label))\n",
    "            rate, wav = wavfile.read(path)\n",
    "            X[i,] = wav.reshape(1, -1)\n",
    "            Y[i,] = to_categorical(label, num_classes=self.n_classes)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.wav_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    src_root = args.src_root\n",
    "    sr = args.sample_rate\n",
    "    dt = args.delta_time\n",
    "    batch_size = args.batch_size\n",
    "    model_type = args.model_type\n",
    "    params = {'N_CLASSES':len(os.listdir(args.src_root)),\n",
    "              'SR':sr,\n",
    "              'DT':dt}\n",
    "    models = {'conv1d':Conv1D(**params),\n",
    "              'conv2d':Conv2D(**params),\n",
    "              'lstm':  LSTM(**params)}\n",
    "    assert model_type in models.keys(), '{} not an available model'.format(model_type)\n",
    "    csv_path = os.path.join('logs', '{}_history.csv'.format(model_type))\n",
    "\n",
    "    wav_paths = glob('{}/**'.format(src_root), recursive=True)\n",
    "    wav_paths = [x.replace(os.sep, '/') for x in wav_paths if '.wav' in x]\n",
    "    #print(wav_paths)\n",
    "    classes = sorted(os.listdir(args.src_root))\n",
    "    le = LabelEncoder()\n",
    "    le.fit(classes)\n",
    "    labels = [os.path.split(x)[0].split('/')[-1] for x in wav_paths]\n",
    "    labels = le.transform(labels)\n",
    "    wav_train, wav_val, label_train, label_val = train_test_split(wav_paths,\n",
    "                                                                  labels,\n",
    "                                                                  test_size=0.2,\n",
    "                                                                  random_state=0)\n",
    "\n",
    "    assert len(label_train) >= args.batch_size, 'Number of train samples must be >= batch_size'\n",
    "    if len(set(label_train)) != params['N_CLASSES']:\n",
    "        warnings.warn('Found {}/{} classes in training data. Increase data size or change random_state.')\n",
    "    if len(set(label_val)) != params['N_CLASSES']:\n",
    "        warnings.warn('Found {}/{} classes in validation data. Increase data size or change random_state.')\n",
    "\n",
    "    tg = DataGenerator(wav_train, label_train, sr, dt,\n",
    "                       params['N_CLASSES'], batch_size=batch_size)\n",
    "    vg = DataGenerator(wav_val, label_val, sr, dt,\n",
    "                       params['N_CLASSES'], batch_size=batch_size)\n",
    "    model = models[model_type]\n",
    "    cp = ModelCheckpoint('models/{}.h5'.format(model_type), monitor='val_loss',\n",
    "                         save_best_only=True, save_weights_only=False,\n",
    "                         mode='auto', save_freq='epoch', verbose=1)\n",
    "    csv_logger = CSVLogger(csv_path, append=False)\n",
    "    history = model.fit(tg, validation_data=vg,\n",
    "                  epochs=60, verbose=1,\n",
    "                  callbacks=[csv_logger, cp])\n",
    "    # 绘制训练 & 验证的准确率值\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # 绘制训练 & 验证的损失值\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george/tfenv/lib/python3.6/site-packages/librosa/filters.py:196: FutureWarning: norm=1 behavior will change in librosa 0.8.0. To maintain forward compatibility, use norm='slaney' instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"2d_convolution\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 1, 64000)]        0         \n",
      "_________________________________________________________________\n",
      "melbands (Melspectrogram)    (None, 128, 400, 1)       296064    \n",
      "_________________________________________________________________\n",
      "batch_norm (Normalization2D) (None, 128, 400, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_tanh (Conv2D)         (None, 128, 400, 8)       400       \n",
      "_________________________________________________________________\n",
      "max_pool_2d_1 (MaxPooling2D) (None, 64, 200, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_relu_1 (Conv2D)       (None, 64, 200, 16)       3216      \n",
      "_________________________________________________________________\n",
      "max_pool_2d_2 (MaxPooling2D) (None, 32, 100, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_relu_2 (Conv2D)       (None, 32, 100, 16)       2320      \n",
      "_________________________________________________________________\n",
      "max_pool_2d_3 (MaxPooling2D) (None, 16, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_relu_3 (Conv2D)       (None, 16, 50, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pool_2d_4 (MaxPooling2D) (None, 8, 25, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_relu_4 (Conv2D)       (None, 8, 25, 32)         9248      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                409664    \n",
      "_________________________________________________________________\n",
      "softmax (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 725,942\n",
      "Trainable params: 725,942\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 1.7810 - accuracy: 0.2045\n",
      "Epoch 00001: val_loss improved from inf to 1.76951, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 52ms/step - loss: 1.7810 - accuracy: 0.2044 - val_loss: 1.7695 - val_accuracy: 0.2188\n",
      "Epoch 2/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 1.7234 - accuracy: 0.2515\n",
      "Epoch 00002: val_loss improved from 1.76951 to 1.67043, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 1.7234 - accuracy: 0.2515 - val_loss: 1.6704 - val_accuracy: 0.2882\n",
      "Epoch 3/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 1.6463 - accuracy: 0.2992\n",
      "Epoch 00003: val_loss improved from 1.67043 to 1.60146, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 1.6463 - accuracy: 0.2992 - val_loss: 1.6015 - val_accuracy: 0.3457\n",
      "Epoch 4/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 1.5934 - accuracy: 0.3398\n",
      "Epoch 00004: val_loss improved from 1.60146 to 1.54785, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 1.5934 - accuracy: 0.3398 - val_loss: 1.5478 - val_accuracy: 0.3765\n",
      "Epoch 5/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 1.5388 - accuracy: 0.3727\n",
      "Epoch 00005: val_loss improved from 1.54785 to 1.52266, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 1.5387 - accuracy: 0.3729 - val_loss: 1.5227 - val_accuracy: 0.3814\n",
      "Epoch 6/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 1.4751 - accuracy: 0.4069\n",
      "Epoch 00006: val_loss improved from 1.52266 to 1.43722, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 1.4753 - accuracy: 0.4072 - val_loss: 1.4372 - val_accuracy: 0.4266\n",
      "Epoch 7/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 1.4111 - accuracy: 0.4357\n",
      "Epoch 00007: val_loss improved from 1.43722 to 1.38643, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 1.4111 - accuracy: 0.4357 - val_loss: 1.3864 - val_accuracy: 0.4591\n",
      "Epoch 8/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 1.3626 - accuracy: 0.4654\n",
      "Epoch 00008: val_loss improved from 1.38643 to 1.35094, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 1.3626 - accuracy: 0.4654 - val_loss: 1.3509 - val_accuracy: 0.4807\n",
      "Epoch 9/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 1.3136 - accuracy: 0.4812\n",
      "Epoch 00009: val_loss improved from 1.35094 to 1.31647, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 1.3136 - accuracy: 0.4812 - val_loss: 1.3165 - val_accuracy: 0.4856\n",
      "Epoch 10/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 1.2715 - accuracy: 0.5031\n",
      "Epoch 00010: val_loss improved from 1.31647 to 1.27202, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 1.2720 - accuracy: 0.5028 - val_loss: 1.2720 - val_accuracy: 0.5144\n",
      "Epoch 11/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 1.2172 - accuracy: 0.5331\n",
      "Epoch 00011: val_loss improved from 1.27202 to 1.20737, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 1.2172 - accuracy: 0.5331 - val_loss: 1.2074 - val_accuracy: 0.5273\n",
      "Epoch 12/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 1.1765 - accuracy: 0.5422\n",
      "Epoch 00012: val_loss did not improve from 1.20737\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 1.1765 - accuracy: 0.5422 - val_loss: 1.2242 - val_accuracy: 0.5188\n",
      "Epoch 13/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 1.1312 - accuracy: 0.5626\n",
      "Epoch 00013: val_loss improved from 1.20737 to 1.14773, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 1.1312 - accuracy: 0.5626 - val_loss: 1.1477 - val_accuracy: 0.5541\n",
      "Epoch 14/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 1.0800 - accuracy: 0.5915\n",
      "Epoch 00014: val_loss did not improve from 1.14773\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 1.0801 - accuracy: 0.5914 - val_loss: 1.1569 - val_accuracy: 0.5672\n",
      "Epoch 15/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 1.0488 - accuracy: 0.6070\n",
      "Epoch 00015: val_loss improved from 1.14773 to 1.09629, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 1.0488 - accuracy: 0.6067 - val_loss: 1.0963 - val_accuracy: 0.5898\n",
      "Epoch 16/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 1.0012 - accuracy: 0.6273\n",
      "Epoch 00016: val_loss improved from 1.09629 to 1.05467, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 1.0018 - accuracy: 0.6272 - val_loss: 1.0547 - val_accuracy: 0.6034\n",
      "Epoch 17/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.9679 - accuracy: 0.6391\n",
      "Epoch 00017: val_loss improved from 1.05467 to 0.99857, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 52ms/step - loss: 0.9679 - accuracy: 0.6391 - val_loss: 0.9986 - val_accuracy: 0.6319\n",
      "Epoch 18/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.9394 - accuracy: 0.6489\n",
      "Epoch 00018: val_loss did not improve from 0.99857\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.9392 - accuracy: 0.6488 - val_loss: 1.0144 - val_accuracy: 0.6213\n",
      "Epoch 19/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.8903 - accuracy: 0.6768\n",
      "Epoch 00019: val_loss improved from 0.99857 to 0.97061, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.8903 - accuracy: 0.6768 - val_loss: 0.9706 - val_accuracy: 0.6441\n",
      "Epoch 20/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.8468 - accuracy: 0.6912\n",
      "Epoch 00020: val_loss improved from 0.97061 to 0.94297, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.8468 - accuracy: 0.6912 - val_loss: 0.9430 - val_accuracy: 0.6483\n",
      "Epoch 21/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.8358 - accuracy: 0.6986\n",
      "Epoch 00021: val_loss improved from 0.94297 to 0.94115, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.8357 - accuracy: 0.6985 - val_loss: 0.9412 - val_accuracy: 0.6518\n",
      "Epoch 22/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.7851 - accuracy: 0.7161\n",
      "Epoch 00022: val_loss improved from 0.94115 to 0.89879, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.7851 - accuracy: 0.7161 - val_loss: 0.8988 - val_accuracy: 0.6694\n",
      "Epoch 23/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.7355 - accuracy: 0.7396\n",
      "Epoch 00023: val_loss improved from 0.89879 to 0.86430, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.7355 - accuracy: 0.7396 - val_loss: 0.8643 - val_accuracy: 0.6768\n",
      "Epoch 24/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.7080 - accuracy: 0.7469\n",
      "Epoch 00024: val_loss improved from 0.86430 to 0.85337, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 52ms/step - loss: 0.7075 - accuracy: 0.7471 - val_loss: 0.8534 - val_accuracy: 0.6907\n",
      "Epoch 25/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.6789 - accuracy: 0.7617\n",
      "Epoch 00025: val_loss improved from 0.85337 to 0.84947, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.6789 - accuracy: 0.7617 - val_loss: 0.8495 - val_accuracy: 0.6865\n",
      "Epoch 26/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.6411 - accuracy: 0.7753\n",
      "Epoch 00026: val_loss improved from 0.84947 to 0.79202, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.6407 - accuracy: 0.7754 - val_loss: 0.7920 - val_accuracy: 0.7173\n",
      "Epoch 27/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.6291 - accuracy: 0.7795\n",
      "Epoch 00027: val_loss improved from 0.79202 to 0.78204, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 52ms/step - loss: 0.6289 - accuracy: 0.7796 - val_loss: 0.7820 - val_accuracy: 0.7195\n",
      "Epoch 28/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.6052 - accuracy: 0.7959\n",
      "Epoch 00028: val_loss improved from 0.78204 to 0.76718, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.6055 - accuracy: 0.7958 - val_loss: 0.7672 - val_accuracy: 0.7215\n",
      "Epoch 29/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.5820 - accuracy: 0.7984\n",
      "Epoch 00029: val_loss did not improve from 0.76718\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.5818 - accuracy: 0.7985 - val_loss: 0.7794 - val_accuracy: 0.7259\n",
      "Epoch 30/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.5540 - accuracy: 0.8091\n",
      "Epoch 00030: val_loss improved from 0.76718 to 0.75888, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.5540 - accuracy: 0.8091 - val_loss: 0.7589 - val_accuracy: 0.7324\n",
      "Epoch 31/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.5422 - accuracy: 0.8123\n",
      "Epoch 00031: val_loss improved from 0.75888 to 0.73197, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 52ms/step - loss: 0.5422 - accuracy: 0.8123 - val_loss: 0.7320 - val_accuracy: 0.7426\n",
      "Epoch 32/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.5159 - accuracy: 0.8264\n",
      "Epoch 00032: val_loss improved from 0.73197 to 0.71582, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.5160 - accuracy: 0.8263 - val_loss: 0.7158 - val_accuracy: 0.7525\n",
      "Epoch 33/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.4957 - accuracy: 0.8314\n",
      "Epoch 00033: val_loss improved from 0.71582 to 0.70506, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.4962 - accuracy: 0.8313 - val_loss: 0.7051 - val_accuracy: 0.7527\n",
      "Epoch 34/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.4765 - accuracy: 0.8424\n",
      "Epoch 00034: val_loss improved from 0.70506 to 0.69792, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.4765 - accuracy: 0.8423 - val_loss: 0.6979 - val_accuracy: 0.7626\n",
      "Epoch 35/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.4522 - accuracy: 0.8510\n",
      "Epoch 00035: val_loss improved from 0.69792 to 0.68373, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 52ms/step - loss: 0.4522 - accuracy: 0.8510 - val_loss: 0.6837 - val_accuracy: 0.7609\n",
      "Epoch 36/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.4348 - accuracy: 0.8573\n",
      "Epoch 00036: val_loss improved from 0.68373 to 0.66761, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.4347 - accuracy: 0.8575 - val_loss: 0.6676 - val_accuracy: 0.7728\n",
      "Epoch 37/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.4109 - accuracy: 0.8675\n",
      "Epoch 00037: val_loss improved from 0.66761 to 0.64888, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.4112 - accuracy: 0.8673 - val_loss: 0.6489 - val_accuracy: 0.7775\n",
      "Epoch 38/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.4041 - accuracy: 0.8696\n",
      "Epoch 00038: val_loss did not improve from 0.64888\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.4042 - accuracy: 0.8697 - val_loss: 0.6550 - val_accuracy: 0.7778\n",
      "Epoch 39/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.8759\n",
      "Epoch 00039: val_loss improved from 0.64888 to 0.64792, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.3813 - accuracy: 0.8759 - val_loss: 0.6479 - val_accuracy: 0.7800\n",
      "Epoch 40/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.3648 - accuracy: 0.8844\n",
      "Epoch 00040: val_loss improved from 0.64792 to 0.60026, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 52ms/step - loss: 0.3643 - accuracy: 0.8846 - val_loss: 0.6003 - val_accuracy: 0.7902\n",
      "Epoch 41/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.3565 - accuracy: 0.8882\n",
      "Epoch 00041: val_loss improved from 0.60026 to 0.59659, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.3565 - accuracy: 0.8882 - val_loss: 0.5966 - val_accuracy: 0.7954\n",
      "Epoch 42/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.3427 - accuracy: 0.8965\n",
      "Epoch 00042: val_loss improved from 0.59659 to 0.58800, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.3422 - accuracy: 0.8966 - val_loss: 0.5880 - val_accuracy: 0.8038\n",
      "Epoch 43/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.3223 - accuracy: 0.9019\n",
      "Epoch 00043: val_loss did not improve from 0.58800\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.3224 - accuracy: 0.9018 - val_loss: 0.5897 - val_accuracy: 0.8006\n",
      "Epoch 44/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.3178 - accuracy: 0.9060\n",
      "Epoch 00044: val_loss improved from 0.58800 to 0.57893, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 52ms/step - loss: 0.3178 - accuracy: 0.9060 - val_loss: 0.5789 - val_accuracy: 0.8041\n",
      "Epoch 45/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.3059 - accuracy: 0.9067\n",
      "Epoch 00045: val_loss did not improve from 0.57893\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.3059 - accuracy: 0.9067 - val_loss: 0.5856 - val_accuracy: 0.8008\n",
      "Epoch 46/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.2931 - accuracy: 0.9118\n",
      "Epoch 00046: val_loss improved from 0.57893 to 0.57881, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.2931 - accuracy: 0.9119 - val_loss: 0.5788 - val_accuracy: 0.8095\n",
      "Epoch 47/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.2834 - accuracy: 0.9162\n",
      "Epoch 00047: val_loss improved from 0.57881 to 0.57575, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.2834 - accuracy: 0.9162 - val_loss: 0.5757 - val_accuracy: 0.8085\n",
      "Epoch 48/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.2722 - accuracy: 0.9212\n",
      "Epoch 00048: val_loss did not improve from 0.57575\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.2722 - accuracy: 0.9212 - val_loss: 0.5768 - val_accuracy: 0.8095\n",
      "Epoch 49/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.2663 - accuracy: 0.9222\n",
      "Epoch 00049: val_loss improved from 0.57575 to 0.56031, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 52ms/step - loss: 0.2666 - accuracy: 0.9221 - val_loss: 0.5603 - val_accuracy: 0.8189\n",
      "Epoch 50/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.2606 - accuracy: 0.9252\n",
      "Epoch 00050: val_loss did not improve from 0.56031\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.2606 - accuracy: 0.9252 - val_loss: 0.5606 - val_accuracy: 0.8204\n",
      "Epoch 51/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.2459 - accuracy: 0.9311\n",
      "Epoch 00051: val_loss improved from 0.56031 to 0.54397, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 52ms/step - loss: 0.2459 - accuracy: 0.9311 - val_loss: 0.5440 - val_accuracy: 0.8182\n",
      "Epoch 52/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.9312\n",
      "Epoch 00052: val_loss did not improve from 0.54397\n",
      "255/255 [==============================] - 13s 52ms/step - loss: 0.2423 - accuracy: 0.9312 - val_loss: 0.5553 - val_accuracy: 0.8212\n",
      "Epoch 53/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.2417 - accuracy: 0.9315\n",
      "Epoch 00053: val_loss did not improve from 0.54397\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.2419 - accuracy: 0.9314 - val_loss: 0.5443 - val_accuracy: 0.8237\n",
      "Epoch 54/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.2257 - accuracy: 0.9391\n",
      "Epoch 00054: val_loss improved from 0.54397 to 0.53778, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 52ms/step - loss: 0.2257 - accuracy: 0.9391 - val_loss: 0.5378 - val_accuracy: 0.8279\n",
      "Epoch 55/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.2263 - accuracy: 0.9391\n",
      "Epoch 00055: val_loss improved from 0.53778 to 0.53561, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 52ms/step - loss: 0.2263 - accuracy: 0.9391 - val_loss: 0.5356 - val_accuracy: 0.8237\n",
      "Epoch 56/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.2158 - accuracy: 0.9419\n",
      "Epoch 00056: val_loss improved from 0.53561 to 0.53282, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.2158 - accuracy: 0.9419 - val_loss: 0.5328 - val_accuracy: 0.8279\n",
      "Epoch 57/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.2071 - accuracy: 0.9475\n",
      "Epoch 00057: val_loss improved from 0.53282 to 0.52298, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 52ms/step - loss: 0.2071 - accuracy: 0.9475 - val_loss: 0.5230 - val_accuracy: 0.8311\n",
      "Epoch 58/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.2112 - accuracy: 0.9469\n",
      "Epoch 00058: val_loss improved from 0.52298 to 0.51781, saving model to models/conv2d.h5\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.2112 - accuracy: 0.9469 - val_loss: 0.5178 - val_accuracy: 0.8306\n",
      "Epoch 59/60\n",
      "255/255 [==============================] - ETA: 0s - loss: 0.2022 - accuracy: 0.9491\n",
      "Epoch 00059: val_loss did not improve from 0.51781\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.2022 - accuracy: 0.9491 - val_loss: 0.5371 - val_accuracy: 0.8304\n",
      "Epoch 60/60\n",
      "254/255 [============================>.] - ETA: 0s - loss: 0.1943 - accuracy: 0.9533\n",
      "Epoch 00060: val_loss did not improve from 0.51781\n",
      "255/255 [==============================] - 13s 51ms/step - loss: 0.1942 - accuracy: 0.9534 - val_loss: 0.5240 - val_accuracy: 0.8242\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-ad9dbd36d882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-78e22d1e04ad>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     88\u001b[0m                   callbacks=[csv_logger, cp])\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# 绘制训练 & 验证的准确率值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Audio Classification Training')\n",
    "    parser.add_argument('--model_type', type=str, default='conv2d',\n",
    "                        help='model to run. i.e. conv1d, conv2d, lstm')\n",
    "    parser.add_argument('--src_root', type=str, default='data/clean',\n",
    "                        help='directory of audio files in total duration')\n",
    "    parser.add_argument('--batch_size', type=int, default=64,\n",
    "                        help='batch size')\n",
    "    parser.add_argument('--delta_time', '-dt', type=float, default=4.0,\n",
    "                        help='time in seconds to sample audio')\n",
    "    parser.add_argument('--sample_rate', '-sr', type=int, default=16000,\n",
    "                        help='sample rate of clean audio')\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/tmp/model1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow3",
   "language": "python",
   "name": "tensorflow3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
