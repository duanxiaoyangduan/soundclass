{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from kapre.augmentation import AdditiveNoise\n",
    "from kapre.utils import Normalization2D\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2D(N_CLASSES=6, SR=16000, DT=1.0):\n",
    "    initializer = tf.keras.initializers.TruncatedNormal(seed=None)\n",
    "    i = layers.Input(shape=(1, int(SR*DT)), name='input')\n",
    "    x = BatchNormalization()(i)\n",
    "    x = Melspectrogram(n_dft=512, n_hop=160,\n",
    "                       padding='same', sr=SR, n_mels=128,\n",
    "                       fmin=0.0, fmax=SR/2, power_melgram=2.0,\n",
    "                       return_decibel_melgram=True, trainable_fb=False,\n",
    "                       trainable_kernel=False,\n",
    "                       name='melbands')(x)\n",
    "    x = AdditiveNoise(power=10., random_gain=True, noise_type='white')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = layers.Conv2D(8, kernel_size=(7,7), activation='relu', padding='same',kernel_initializer=initializer, name='conv2d_relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same',  name='max_pool_2d_1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = layers.Conv2D(16, kernel_size=(5,5), activation='relu', padding='same', kernel_initializer=initializer, name='conv2d_relu_1')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = layers.Conv2D(32, kernel_size=(3,3), activation='relu', kernel_initializer=initializer, padding='same', name='conv2d_relu_2')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_3')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = layers.Conv2D(32, kernel_size=(3,3), activation='relu', kernel_initializer=initializer, padding='same', name='conv2d_relu_3')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_4')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dropout(rate=0.2)(x)\n",
    "    x = layers.Dense(64, activation='relu', kernel_initializer=initializer, name='dense1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = layers.Dense(64, activation='relu', kernel_initializer=initializer, name='dense2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    o = layers.Dense(N_CLASSES, activation='softmax', kernel_initializer=initializer, name='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=i, outputs=o, name='2d_convolution')\n",
    "    model.summary()\n",
    "    initial_learning_rate = 0.04\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate,\n",
    "        decay_steps=500,\n",
    "        decay_rate=0.96,\n",
    "        staircase=True)\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adagrad(learning_rate=lr_schedule)\n",
    "    model.compile(optimizer= opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def Conv1D(N_CLASSES=6, SR=16000, DT=1.0):\n",
    "    i = layers.Input(shape=(1, int(SR*DT)), name='input')\n",
    "    x = Melspectrogram(n_dft=512, n_hop=160,\n",
    "                       padding='same', sr=SR, n_mels=128,\n",
    "                       fmin=0.0, fmax=SR/2, power_melgram=2.0,\n",
    "                       return_decibel_melgram=True, trainable_fb=False,\n",
    "                       trainable_kernel=False,\n",
    "                       name='melbands')(i)\n",
    "    x = Normalization2D(str_axis='batch', name='batch_norm')(x)\n",
    "    x = layers.Permute((2,1,3), name='permute')(x)\n",
    "    x = TimeDistributed(layers.Conv1D(8, kernel_size=(4), activation='tanh'), name='td_conv_1d_tanh')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_1')(x)\n",
    "    x = TimeDistributed(layers.Conv1D(16, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_1')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_2')(x)\n",
    "    x = TimeDistributed(layers.Conv1D(32, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_2')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_3')(x)\n",
    "    x = TimeDistributed(layers.Conv1D(64, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_3')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_4')(x)\n",
    "    x = TimeDistributed(layers.Conv1D(128, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_4')(x)\n",
    "    x = layers.GlobalMaxPooling2D(name='global_max_pooling_2d')(x)\n",
    "    x = layers.Dropout(rate=0.1, name='dropout')(x)\n",
    "    x = layers.Dense(64, activation='relu', activity_regularizer=l2(0.001), name='dense')(x)\n",
    "    o = layers.Dense(N_CLASSES, activation='softmax', name='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=i, outputs=o, name='1d_convolution')\n",
    "    #model.summary()\n",
    "    opt = tf.keras.optimizers.Adam(0.00001)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def LSTM(N_CLASSES=6, SR=16000, DT=1.0):\n",
    "    i = layers.Input(shape=(1, int(SR*DT)), name='input')\n",
    "    x = Melspectrogram(n_dft=512, n_hop=160,\n",
    "                       padding='same', sr=SR, n_mels=128,\n",
    "                       fmin=0.0, fmax=SR/2, power_melgram=2.0,\n",
    "                       return_decibel_melgram=True, trainable_fb=False,\n",
    "                       trainable_kernel=False,\n",
    "                       name='melbands')(i)\n",
    "    x = Normalization2D(str_axis='batch', name='batch_norm')(x)\n",
    "    x = layers.Permute((2,1,3), name='permute')(x)\n",
    "    x = TimeDistributed(layers.Reshape((-1,)), name='reshape')(x)\n",
    "    s = TimeDistributed(layers.Dense(64, activation='tanh'),\n",
    "                        name='td_dense_tanh')(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(32, return_sequences=True),\n",
    "                             name='bidirectional_lstm')(s)\n",
    "    x = layers.concatenate([s, x], axis=2, name='skip_connection')\n",
    "    x = layers.Dense(64, activation='relu', name='dense_1_relu')(x)\n",
    "    x = layers.MaxPooling1D(name='max_pool_1d')(x)\n",
    "    x = layers.Dense(32, activation='relu', name='dense_2_relu')(x)\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dropout(rate=0.2, name='dropout')(x)\n",
    "    x = layers.Dense(32, activation='relu',\n",
    "                         activity_regularizer=l2(0.003),\n",
    "                         name='dense_3_relu')(x)\n",
    "    o = layers.Dense(N_CLASSES, activation='softmax', name='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=i, outputs=o, name='long_short_term_memory')\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(0.0008)\n",
    "    model.compile(optimizer= 'Adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from models import Conv1D, Conv2D, LSTM\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, wav_paths, labels, sr, dt, n_classes,\n",
    "                 batch_size=32, shuffle=True):\n",
    "        self.wav_paths = wav_paths\n",
    "        self.labels = labels\n",
    "        self.sr = sr\n",
    "        self.dt = dt\n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = True\n",
    "        self.on_epoch_end()\n",
    "    def __len__(self):\n",
    "        return int(np.floor(8*len(self.wav_paths) / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        #print(index)\n",
    "        wav_paths = [self.wav_paths[k] for k in indexes]\n",
    "        labels = [self.labels[k] for k in indexes]\n",
    "\n",
    "        # generate a batch of time data\n",
    "        X = np.empty((self.batch_size, 1, int(self.sr*self.dt)), dtype=np.int16)\n",
    "        Y = np.empty((self.batch_size, self.n_classes), dtype=np.float32)\n",
    "\n",
    "        for i, (path, label) in enumerate(zip(wav_paths, labels)):\n",
    "            rate, wav = wavfile.read(path)\n",
    "            #print(wav.shape)\n",
    "            #print(path+str(label))\n",
    "            sample_length = int(rate*self.dt)\n",
    "                    # generate a batch of time data\n",
    "            X = np.empty((self.batch_size, 1, int(self.sr*self.dt)), dtype=np.int16)\n",
    "            Y = np.empty((self.batch_size, self.n_classes), dtype=np.float32)\n",
    "            \n",
    "            if sample_length < wav.shape[0]:\n",
    "                rand_index = np.random.randint(0, wav.shape[0]-sample_length)\n",
    "                #rand_index = 1\n",
    "                sample = wav[rand_index : rand_index+sample_length]\n",
    "                \n",
    "            else:\n",
    "                #rand_index = 1\n",
    "                rand_index = np.random.randint(0, sample_length-wav.shape[0])\n",
    "                sample = np.pad(wav, (rand_index, sample_length-wav.shape[0]-rand_index), 'constant', constant_values=0)\n",
    "            #print(sample)\n",
    "            #print(rand_index)\n",
    "            #print(path+str(label))\n",
    "               \n",
    "            #print(sample.shape) \n",
    "            \n",
    "            X[i,] = sample.reshape(1, -1)\n",
    "            #print(X[i]) \n",
    "            Y[i,] = to_categorical(label, num_classes=self.n_classes)\n",
    "            #time.sleep(0.1)\n",
    "        return X, Y\n",
    "        \n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.wav_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "\n",
    "def train(args):\n",
    "    src_root = args.src_root\n",
    "    sr = args.sample_rate\n",
    "    dt = args.delta_time\n",
    "    batch_size = args.batch_size\n",
    "    model_type = args.model_type\n",
    "    params = {'N_CLASSES':len(os.listdir(args.src_root)),\n",
    "              'SR':sr,\n",
    "              'DT':dt}\n",
    "    models = {'conv1d':Conv1D(**params),\n",
    "              'conv2d':Conv2D(**params),\n",
    "              'lstm':  LSTM(**params)}\n",
    "    assert model_type in models.keys(), '{} not an available model'.format(model_type)\n",
    "    csv_path = os.path.join('logs', '{}_history.csv'.format(model_type))\n",
    "\n",
    "    wav_paths = glob('{}/**'.format(src_root), recursive=True)\n",
    "    wav_paths = [x.replace(os.sep, '/') for x in wav_paths if '.wav' in x]\n",
    "    classes = sorted(os.listdir(args.src_root))\n",
    "    le = LabelEncoder()\n",
    "    le.fit(classes)\n",
    "    labels = [os.path.split(x)[0].split('/')[-1] for x in wav_paths]\n",
    "    labels = le.transform(labels)\n",
    "\n",
    "    wav_train, wav_val, label_train, label_val = train_test_split(wav_paths,\n",
    "                                                                  labels,\n",
    "                                                                  test_size=0.2,\n",
    "                                                                  random_state=0)\n",
    "\n",
    "    assert len(label_train) >= args.batch_size, 'number of train samples must be >= batch_size'\n",
    "\n",
    "    tg = DataGenerator(wav_train, label_train, sr, dt,\n",
    "                       len(set(label_train)), batch_size=batch_size)\n",
    "    vg = DataGenerator(wav_val, label_val, sr, dt,\n",
    "                       len(set(label_val)), batch_size=batch_size)\n",
    "\n",
    "    model = models[model_type]\n",
    "    cp = ModelCheckpoint('models/{}.h5'.format(model_type), monitor='val_loss',\n",
    "                         save_best_only=True, save_weights_only=False,\n",
    "                         mode='auto', save_freq='epoch', verbose=1)\n",
    "    csv_logger = CSVLogger(csv_path, append=False)\n",
    "    model.fit(tg, validation_data=vg,\n",
    "              epochs=80, verbose=1,\n",
    "              callbacks=[csv_logger, cp])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"2d_convolution\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 1, 64000)]        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_429 (Bat (None, 1, 64000)          256000    \n",
      "_________________________________________________________________\n",
      "melbands (Melspectrogram)    (None, 128, 400, 1)       296064    \n",
      "_________________________________________________________________\n",
      "batch_normalization_430 (Bat (None, 128, 400, 1)       4         \n",
      "_________________________________________________________________\n",
      "conv2d_relu (Conv2D)         (None, 128, 400, 8)       400       \n",
      "_________________________________________________________________\n",
      "max_pool_2d_1 (MaxPooling2D) (None, 64, 200, 8)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_431 (Bat (None, 64, 200, 8)        32        \n",
      "_________________________________________________________________\n",
      "conv2d_relu_1 (Conv2D)       (None, 64, 200, 16)       3216      \n",
      "_________________________________________________________________\n",
      "max_pool_2d_2 (MaxPooling2D) (None, 32, 100, 16)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_432 (Bat (None, 32, 100, 16)       64        \n",
      "_________________________________________________________________\n",
      "conv2d_relu_2 (Conv2D)       (None, 32, 100, 32)       4640      \n",
      "_________________________________________________________________\n",
      "max_pool_2d_3 (MaxPooling2D) (None, 16, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_433 (Bat (None, 16, 50, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_relu_3 (Conv2D)       (None, 16, 50, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pool_2d_4 (MaxPooling2D) (None, 8, 25, 32)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_434 (Bat (None, 8, 25, 32)         128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 64)                409664    \n",
      "_________________________________________________________________\n",
      "batch_normalization_435 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_436 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "softmax (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 984,650\n",
      "Trainable params: 856,216\n",
      "Non-trainable params: 128,434\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "365/367 [============================>.] - ETA: 0s - loss: 1.6254 - accuracy: 0.3620\n",
      "Epoch 00001: val_loss improved from inf to 2.19894, saving model to models/conv2d.h5\n",
      "367/367 [==============================] - 7s 19ms/step - loss: 1.6251 - accuracy: 0.3617 - val_loss: 2.1989 - val_accuracy: 0.2364\n",
      "Epoch 2/60\n",
      "364/367 [============================>.] - ETA: 0s - loss: 1.6136 - accuracy: 0.3546\n",
      "Epoch 00002: val_loss improved from 2.19894 to 2.12244, saving model to models/conv2d.h5\n",
      "367/367 [==============================] - 7s 18ms/step - loss: 1.6122 - accuracy: 0.3554 - val_loss: 2.1224 - val_accuracy: 0.1284\n",
      "Epoch 3/60\n",
      "364/367 [============================>.] - ETA: 0s - loss: 1.6277 - accuracy: 0.3535\n",
      "Epoch 00003: val_loss improved from 2.12244 to 2.10135, saving model to models/conv2d.h5\n",
      "367/367 [==============================] - 7s 19ms/step - loss: 1.6260 - accuracy: 0.3549 - val_loss: 2.1014 - val_accuracy: 0.1923\n",
      "Epoch 4/60\n",
      "364/367 [============================>.] - ETA: 0s - loss: 1.6882 - accuracy: 0.3017"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-4bf53da83f87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-146-36b7052b09ec>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    103\u001b[0m     model.fit(tg, validation_data=vg,\n\u001b[1;32m    104\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m               callbacks=[csv_logger, cp])\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    870\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m    873\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 step_num=step):\n\u001b[1;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfenv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfenv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/tfenv/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfenv/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfenv/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfenv/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/tfenv/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Audio Classification Training')\n",
    "    parser.add_argument('--model_type', type=str, default='conv2d',\n",
    "                        help='model to run. i.e. conv1d, conv2d, lstm')\n",
    "    parser.add_argument('--src_root', type=str, default='data/clean1',\n",
    "                        help='directory of audio files in total duration')\n",
    "    parser.add_argument('--batch_size', type=int, default=64,\n",
    "                        help='batch size')\n",
    "    parser.add_argument('--delta_time', '-dt', type=float, default=4,\n",
    "                        help='time in seconds to sample audio')\n",
    "    parser.add_argument('--sample_rate', '-sr', type=int, default=16000,\n",
    "                        help='sample rate of clean audio')\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate, wav = wavfile.read(\"data/new/awake/awake_0_1.wav\")\n",
    "length = len(wav)/rate\n",
    "print(length)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow3",
   "language": "python",
   "name": "tensorflow3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
